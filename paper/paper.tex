\documentclass[twocolumn]{article}
\usepackage{verbatim}
\usepackage[utf8x]{inputenc}
\usepackage[a4paper,margin=1.4cm]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{mathpartir}
\usepackage{ amssymb }
\usepackage[makeroom]{cancel}
% \usepackage{minted}
\title{A semantics of core AUTOSAR}
\author{Johan Nordlander \and Patrik Jansson}
%%%%%%%
\input{macros.tex}
\input{semantics.tex}

\setlength{\parindent}{0pt}
\setlength{\parskip}{4pt plus 2pt minus 1pt}

\begin{document}
\maketitle
\begin{abstract}


\end{abstract}

\section{Introduction}
\label{sec:Intro}

The AUTOSAR standard is an open software component architecture for the automotive industry. Its main purpose is to enable interoperability of software modules among different vendors and on heterogeneous platforms, via an extensive set of standardized interfaces and libraries, and a common software development methodology.

The standard has a rather wide scope and covers many features normally associated with complex operating systems, like I/O abstraction, concurrency, communication, distribution and real-time predictability. Unlike existing operating systems, however, AUTOSAR is not de facto defined in terms of a particular implementation. Instead, an explicit goal of AUTOSAR is to constitute an abstract specification that allows multiple and competing realizations, and even systems built as an assembly of fragments from many different (and competing) vendors. Such a goal naturally puts a heavy focus on the standard specification itself.

Unfortunately, the AUTOSAR specification is not very rigorous, despite a sheer size of more than 12,500 pages of text and UML diagrams in total. It is also not very abstract, in that it makes frequent references to assumed implementation techniques for the purpose of defining its semantics. In practice, the AUTOSAR standard becomes blurred with the specific behavior of one's chosen platform and development tools. And because the standard is open to interpretation, the interoperability of software components across tools and platforms is often seriously hampered. What is more, a single software component cannot easily be studied and understood in isolation, since its interactive behavior is only indirectly defined in terms of the concrete C-code and OS tasks that realize it and its interaction environment.

This paper takes an important step towards a remedy to these problems, by contributing a formal specification of a substantial core of the AUTOSAR standard. The formalization covers most of the Software Component Template and its accompanying Run-Time Environment (RTE) (Section~\ref{sec:Calc}), and is able to directly express every legal way a system of software components can evolve at run-time on an arbitrarily fast platform (Section~\ref{sec:Sem}). It can thus serve as a basis for both a concrete AUTOSAR implementation on a specific platform (whose supported behaviors must be a subset of those defined by the formal semantics), and a platform-independent AUTOSAR simulator (where behaviors from the legal set can be picked at random). Examples of semantic derivations and their applications are found in Section~\ref{sec:Examples}.

The semantics has been formalized with the intent to accurately capture the informal meaning of the AUTOSAR standard, although mistakes and misunderstandings are certainly both possible and plausible. A formal notation is nevertheless a good starting point for any discussion on the resolution of such issues. The semantics is furthermore written to be unambiguous, except where concurrent execution should allow for more than one observed behavior. At some points, the AUTOSAR documents have been found unclear; here a specific choice has been made but alternative interpretations will be discussed separately (Section~\ref{sec:DiscAmb}). At other points, the standard documents are clear but the resulting semantics is still dubious. These cases will also be emphasized and discussed, together with suggested ways forward (Section~\ref{sec:DiscImp}).


TODO: Limitations

TODO: Simple examples early (informally)

\section{AUTOSAR}
\label{sec:autosar}

An AUTOSAR model is primarily a structure of interconnected \textbf{software components} (SWCs). Links between SWCs are called \textbf{connectors}, which attach to \textbf{ports} exposed by the SWCs. A port is either \textbf{required} or \textbf{provided}, and then classified according to what \textbf{interface} it exposes: \textbf{sender-receiver}, \textbf{client-server}, \textbf{trigger} and \textbf{mode-switch} are common interface types. A sender-receiver interface is an aggregation of one or more \textbf{data-elements}, with each element characterized by the type of data it carries and optional further communication specification details. A client-server interface likewise consists of one or more \textbf{operations}, that each give the signature of a procedure call and the possible errors that may result.

Some components merely act as containers of other components structures, these are called \textbf{composition} SWCs. In contrast, \textbf{atomic} SWCs define their own behavior in terms of \textbf{runnables} and \textbf{inter-runnable variables}, primarily. A runnable denotes a sequential and (normally) terminating piece of code, although its actual behavioral definition is typically relegated to external C or Matlab files rather than being part of the AUTOSAR model proper. Instead, an AUTOSAR runnable  only provides constraints on what ports and inter-runnable variables the actual implementation can access; as well as \textbf{event} declarations that determine under what conditions it will get executed.

A runnable under execution is called a \textbf{runnable instance}, and these may execute concurrently even if they belong to the same SWC. Each runnable indicates whether or not it may be instantiated concurrently with itself. Runnable code can also use \textbf{exclusive areas} (a form of mutex semaphores) to further control concurrent behavior.

To interact with ports, inter-runnable variables and exclusive areas, runnables use what is abstractly known as the \textbf{virtual function bus} (VFB). Concretely, the VFB takes the shape of a C programming interface to the \textbf{run-time environment} (RTE), custom-generated for each runnable on the basis of its access constraints. Behind the RTE, a collection of OS kernels, communication stacks and other basic software modules implement the VFB services for the platform at hand. Complete AUTOSAR designs also typically contain \textbf{ECU} and \textbf{task assignments}, which are manually built tables that control how SWCs and runnables map onto the available hardware and OS resources, respectively.

AUTOSAR models are completely static, which means that all components, runnables, ports, connectors, etc, are created ahead of execution time. Runnable instances are an exception, but they are only identified by AUTOSAR for conceptual purposes and are never part of any model syntax. This static nature renders AUTOSAR models very suitable to graphical notations, which by far is the most widespread representation format for AUTOSAR models. A graphical model example is shown in Figure~\ref{fig:model}.

TODO: add fig:model

\section{Syntax and preliminaries}
\label{sec:Calc}

The formal approach we have chosen is that of a typical process calculus \cite{TODO}, where a system of concurrent processes evolves in a sequence of atomic steps, as determined by a global set of transition rules. Our process terms correspond to the individual state-carrying parts of an AUTOSAR system, like the runnables, runnable instances, inter-runnable variables and port elements. Each such term is also assigned a constant address parameter for identification purposes.

Components and ports do not carry any dynamic state besides the state of their constituent parts, so they need no explicit representation as process terms. However, in order to still be able to talk about model elements using their locally scoped names, we employ a hierarchical addressing scheme, such that address $\Tr{\V{R}}{\V{I}}$ means runnable \V{R} of component \V{I} and $\Tep{\V{E}}{\V{P}}{\V{I}}$ means element \V{E} of port \V{P} within component \V{I}. We use the following meta-variable conventions:

%
\[
\begin{array}{rcll}
  \V{I} & \in & \text{Component names} \\
  \V{R} & \in & \text{Runnable names} \\
  \V{P} & \in & \text{Port names} \\
  \V{E} & \in & \text{Sender-receiver element names} \\
  \V{O} & \in & \text{Client-server operation names} \\
  \V{S} & \in & \text{Inter-runnable variable names} \\
  \V{X} & \in & \text{Exclusive area names} \\
\\
  \V{A},\V{B} & \in & \text{Addresses} \\
  \V{A},\V{B} & ::= & \Tr{\V{R}}{\V{I}}   \sep   i.p  \sep  \Tep{\V{E}}{\V{P}}{\V{I}}   \sep \Top{\V{O}}{\V{P}}{\V{I}}   \sep   \Ts{\V{S}}{\V{I}}   \sep   \Tx{\V{X}}{\V{I}}   \\
\end{array}
\]
%
Since AUTOSAR components can be arbitrarily nested, the component names \V{I} can also be considered to have a similarly nested internal structure (component \V{I_1} within component \V{I_2} within component \V{I_3}, etc). We can fully ignore this detail here, though, as the hierarchical layout of components in an AUTOSAR system has no run-time implications \cite{TODO2}.

The process terms of our calculus are as follows:
\begin{itemize}
\item $\Trunnable {\Tr r i} t \Act n$  \newline
Dynamic state for runnable $r$ of component $i$, indicating $n$ current instances, $t$ seconds left until next possible instantiation, and activation state $\Act$.
\item $\Trinst {\Tr r i} c \Xs \Code$ \newline
An instance of runnable $r$ of component $i$, currently executing $\Code$ and owning the exclusive areas $\Xs$, possibly running on behalf of client $c$.
\item $\Texcl {\Tx x i} u$ \newline
Exclusive area $x$ of component $i$, with boolean occupation state $u$.
\item $\Tirv {\Ts s i} v$ \newline
Inter-runnable variable $s$ of component $i$, currently holding value $v$.
\item $\Tdelem {\Tep e p i} u v$ \newline
Non-queued sender-receiver data element $e$ in port $p$ of component $i$, currently holding value \V{V} with boolean update status flag $u$.
\item $\Tqelem {\Tep e p i} n \Vs$ \newline
Queued sender-receiver data element $e$ in port $p$ of component $i$ with maximum capacity $n$, currently holding value sequence $\Vs$.
\item $\Toper {\Top o p i} m \Srv$ \newline
Client-server operation $o$ in port $p$ of component $i$, currently holding sequence number $m$ and call state $\Srv$.
\item $\Ttimer {\Tr r i} {t_p} t$ \newline
Periodic timer for runnable $r$ of component $i$, with a period of $t_p$ and $t$ seconds left of its current cycle.
\end{itemize}

In the untyped setting of this report, a value $v$ can be any data item computed and communicated by an AUTOSAR system, including the unit value $\Tvoid$ and the error codes that might be returned from RTE calls. Meta-variables $n$ and $m$ stand for natural numbers, while $u$ and $t$ range over boolean values and (floating point) time values, respectively. The client $c$ of a runnable instance is a tuple holding the address, sequence number and argument value of the current invocation (if the runnable was invoked by a client-server call), or is $\Tvoid$ otherwise. An activation state $\Act$ either toggles between $\Tidle$ and $\Tpending$, or is a sequence of client tuples (in the case of a runnable triggered by client-server calls). A call state $\Srv$ alternates between indicating an ongoing call with a timeout and a finished call with a result value.
Formally,
\[
\begin{array}{rcll}
  v        & \in & \text{Values} \\
  n,m      & \in & \text{Natural numbers} \\
  u        & \in & \text{Boolean values} \\
  t        & \in & \text{Time values} \\
  c        & \in & \text{Clients} \\
  \Act     & \in & \text{Activation states} \\
  \Srv     & \in & \text{Call states} \\ \\
  c        & ::= & \Tclient {\Top o p i} m v \sep \Tvoid \\
  \Act     & ::= & \Tidle \sep \Tpending \sep \Cs \\
  \Srv     & ::= & \Tcalling t \sep \Tdone v
\end{array}
\]
We write $\Vs$ for a sequence of values \V{V}, $\Cs$ for a sequence of clients \V{C}, etc. Sequences may be empty, which is written $\epsilon$. By $\Tlength{\Vs}$ we mean the length of sequence $\Vs$. Left (right) concatenation of an element with a sequence is written $\Tcons{\V{V}}{\V{Vs}}$ ($\Tsnoc{\V{Vs}}{\V{V}}$).

The $\Code$ part of a runnable instance should technically be a representation of the C or Matlab implementation that must accompany an AUTOSAR runnable definition once it is complete. However, since our task in this report is not to investigate the semantics of these languages in any detail, a more abstract notion of executable code will be required.

To this end, we have chosen to ignore all internal computations and just capture the observable effects of runnable execution as a pure sequence of RTE (VFB) calls. And because the result from an RTE call may in general affect subsequent runnable behavior, we use a continuation-passing style where every $\Code$ term except the final function return literally contain the sequence that follows it, as a continuation parameter $\Cont$.
%
\[
\begin{array}{lll}
  \Code & \in & \text{Code}                \\
  \Cont & \in & \text{Values} \rightarrow \text{Code}   \\ \\
  \Code & ::= & \Enter x \Cont               \\
        & |   & \Exit x \Cont                \\
        & |   & \IrvWrite s v \Cont          \\
        & |   & \IrvRead s \Cont             \\
        & |   & \Send {\Te e p} v \Cont      \\
        & |   & \Receive {\Te e p} \Cont     \\
        & |   & \Write {\Te e p} v \Cont     \\
        & |   & \Read {\Te e p} \Cont        \\
        & |   & \Invalidate {\Te e p} \Cont  \\
        & |   & \IsUpdated {\Te e p} \Cont   \\
        & |   & \Call {\To o p} v \Cont      \\
        & |   & \Result {\To o p} \Cont      \\
        & |   & \Return v                    \\
\end{array}
\]

In contrast to code sequences, process terms are completely unordered. This is expressed in the standard process calculus style using an associative operator $\Tpar{}{}$ that allows arbitrary sets of primitive processes to be composed in parallel. This operator also has a left and right unit in the form of process $\Tzero$, which stands for the empty, or terminated, process. The complete grammar for our process terms thus looks as follows:

\[
\begin{array}{rcll}
  \V{P},\V{Q}
        & ::= & \Trunnable a t {\Act} n      \\
        & |   & \Trinst a c {\Xs} {\Code}    \\
        & |   & \Texcl a u                   \\
        & |   & \Tirv a v                    \\
        & |   & \Tdelem a u v                \\
        & |   & \Tqelem a n {\Vs}            \\
        & |   & \Toper a m \Srv              \\
        & |   & \Ttimer a {\V{T_p}} t        \\
        & |   & \Tpar p q                    \\
        & |   & \Tzero                       \\
\end{array}
\]

TODO: links from syntax and concepts introduced here to the AUTOSAR spec

TODO: details on limitations: what's not covered by the calculus


\section{Semantics}
\label{sec:Sem}

Our semantic approach defines the meaning of an AUTOSAR system as the possible chains of state changes that can be applied to the system's initial state; or equivalently, as the set of \emph{traces} that can be generated from the initial process term \V{P_0}. A trace is a possibly infinite sequence of transitions
\[
\begin{array}{c}
  {p_0} \red{l_1} {p_1} \red{l_2} {p_2} \red{l_3} \cdots
\end{array}
\]
where each step
\[
\begin{array}{c}
  {p_{i-1}} \red{l_i} {p_i}
\end{array}
\]
states that the system state captured as process term $p_{i-1}$ can evolve into state $p_i$ by means of a single transition labelled $l_i$.

The label $l$ of a transition can essentially be of two kinds, indicating that the affected process either ``says'' or ``hears'' something during the transition. Such a label always consists of an address $a$ paired with some additional detail $d$. There is also a special form of ``hearing'' that denotes letting time pass and which does not carry any address. The different labels are captured in the following grammar.
\[
\begin{array}{rcll}
  l         & ::= & a!d       & \hspace{4em}\text{Say  \V{A} and \V{D}}   \\
            & |   & a?d       & \hspace{4em}\text{Hear \V{A} and \V{D}}   \\
            & |   & \Tdelta t & \hspace{4em}\text{Let \V{T} seconds pass} \\
\end{array}
\]
The possible forms of the extra label information \V{D} will be introduced as the different transition rules are defined.

Two processes $p$ and $q$ can make transitions in parallel if they agree on what is being said or heard. Just as the saying/hearing intuition suggests, at most one of the processes can have the saying role in such an agreement. The following set of inference rules capture this intuition formally.
{
\renewcommand{\Prule}[2]{#1 \quad \Pif\; #2\\}
\renewcommand{\Tstep}[3]{#1 \red{#2} #3}
\renewcommand\Pcomma{\;\text{and}\;}

\begin{eqnarray}  \CombRed  \notag \end{eqnarray}
}


The effect of these agreement rules closely resembles the idea of a \emph{broadcast}: what one process says may be heard by every other process in a large parallel composition. This behavior serves us well, because in general, what one AUTOSAR runnable does may have impact on many (if not all) parts of the executing system. It is however important not to confuse this broadcasting notion with any particular form of AUTOSAR communication. The way transition labels distribute over the parallel composition operator is merely a technical aspect of our process calculus, and will be used to express several different AUTOSAR communication semantics, among other things.

The initial process $p_0$ is determined fully by the AUTOSAR model under study, as the parallel composition of the following terms:
\begin{enumerate}

\item For each runnable $r$ of each component $i$, a term
\[
\begin{array}{c}
  \Trunnable {\Tr r i} 0 \Act 0
\end{array}
\]
where $\Act$ is $\epsilon$ if $r$ is triggered by an \emph{OperationInvokedEvent}; else $\Act$ is $\Tpending$ if $r$ is triggered by an \emph{InitEvent}; otherwise $\Act$ is $\Tidle$.
% SWS_Rte_03524 (SWS_Rte_03526?) forbids mixing OperationInvokedEvents with other events for the same runnable

\item For each exclusive area $x$ of each atomic component $i$, a term
\[
\begin{array}{c}
  \Texcl {\Tx x i} \Tfalse
\end{array}
\]

\item For each inter-runnable variable $s$ of each atomic component $i$, a term
\[
\begin{array}{c}
  \Tirv {\Ts s i} v
\end{array}
\]
where $v$ is the \emph{initValue} attributed to $s$ if it exists, otherwise $v$ is $\Tvoid$.

\item For each data element $e$ of each required port $p$ of each atomic component $i$, a term
\[
\begin{array}{c}
  \Tqelem {\Tep e p i} n \epsilon
\end{array}
\]
if the \emph{swImplPolicy} attribute of element $e$ is \emph{queued} (with capacity $n$); otherwise, a term
\[
\begin{array}{c}
  \Tdelem {\Tep e p i} \Tfalse \TneverReceived
\end{array}
\]

\item For each operation $o$ of each required port $p$ of each atomic component $i$, a term
\[
\begin{array}{c}
  \Toper{\Top o p i} 0 {\Tdone \Tvoid}
\end{array}
\]

\item For each \emph{TimingEvent} of each runnable $r$ of each atomic component $i$, a term
\[
\begin{array}{c}
  \Ttimer {\Tr r i } {t_p} 0
\end{array}
\]
where $\V{T_p}$ is the period of the event.
%TODO: This means that all timed runnables want to act _immediately_ (at the same time - with no init delay).

\end{enumerate}

The AUTOSAR naming scheme guarantees that all processes terms in such an initial composition will carry unique addresses, with exception of timer terms which share addresses with the runnables they belong to. We will later see how runnable instances reuse the address of their runnables in the same manner.

Some further static model information will also be referenced by the transition rules. We refer to the connectors of a model using a binary relation $\Rightarrow$ on port addresses, where the arrow points in the \emph{provided-to-required} direction. We also assume that $\Rightarrow$ is transitively closed (i.e., it expresses end-to-end connectivity across \emph{Delegation-} as well as \emph{AssemblySwConnector}s), and that every connection $a \Rightarrow b$ is lifted to the \emph{DataElement}s and \emph{ClientServerOperation}s of the connected ports such that
\[
\begin{array}{lll}
  \Tconnect{a.e}{b.e} & \text{for all elements $e$ common to $a$ and $b$} \\
  \Tconnect{a.o}{b.o} & \text{for all operations $o$ common to $a$ and $b$} \\
\end{array}
\]

We expect the implementation of a runnable to be available as a continuation function $\Cont$, even though the real AUTOSAR model will be refering to concrete functions in external C/Matlab files. We will further abstract away from actual numbers of input and output parameters to these functions by assuming that records (structs) are used as the single continuation argument and result whenever the arity so requires. Absent arguments or results will be replaced by the unit value $\Tvoid$.

We write $\Timplementation{i.r}{k}$ to state the assumption that the static AUTOSAR model under study assigns implementation function $k$ to runnable $i.r$. Similar notations will be used to express other references to the underlying static model; for example $\TdataReceivedEvent {i.r} {i.p.e}$ to state that the model allows runnable $i.r$ to be triggered by data reception events on port $i.p.e$. Although the chosen notation is sometimes significantly shorter than the UML/XML-based syntax used in the AUTOSAR specification, the intended meaning should nevertheless be clear.

The semantic transition axioms are written in full in Appendix~\ref{sec:Rules}. We will discuss each group of axioms in turn, starting with the relatively simple behaviour of inter-runnable variables and exclusive areas. In most cases, the driving force behind a transition is some runnable instance wishing to say something which other processes either react to or ignore. How the runnable instances themselves come into existence will be detailed in Section~\ref{sect:SpawnTerm}.

\subsection{Inter-runnable variables}

An inter-runnable variable (irv) represents state that is local to a particular component and accessible by all runnables of that component. Axioms (5) and (7) show the \emph{say} transitions taken by a runnable instance wishing to read and write an irv $s$. In both cases the embedded continuation $k$ is applied to the command result. The corresponding \emph{hear} transitions of an irv appear as rules (6) and (8). Thanks to inference rule (1), a runnable instance and an irv can now engage in a parallel transition, for example expressing the writing of shared data.
$$
\begin{array}{c}
  \Tpar {\Trinst {i.r} c \Xs {\TrteIrvWrite s v k}}
        {\Tirv {i.s} \_} \vspace{0.6ex} \\
  \red {\say {i.s} {\Tirvw v}} \\
  \Tpar {\Trinst {i.r} c \Xs {\Tap k \Tvoid}}
        {\Tirv {i.s} v}
\end{array}
$$
The corresponding read transition looks as follows:
$$
\begin{array}{c}
  \Tpar {\Trinst {i.r} c \Xs {\TrteIrvRead s k}}
        {\Tirv {i.s} v} \vspace{0.6ex} \\
  \red {\say {i.s} {\Tirvr v}} \\
  \Tpar {\Trinst {i.r} c \Xs {\Tap k v}}
        {\Tirv {i.s} v}
\end{array}
$$
Section~\ref{sect:Ignore} will show how examples like these can be extended to the case when both participating processes are embedded in arbitrarily large parallel process compositions.

Note that in the last example above, the read value $v$ flows from the irv process to the runnable instance, even though axiom (6) states that an irv actually \emph{hears} the transition payload $\Tirvr{v}$. This apparent paradox is simply a reminder that the saying/hearing distinction of our calculus is entirely separate from the dataflow patterns it defines.


\subsection{Exclusive areas}

An exclusive area is the AUTOSAR equivalent of a binary semaphore, that can be acquired and released in an atomic fashion by competing runnable instances. Axiom (9) states that a runnable instance wishing to enter exclusive area $x$ may successfully proceed to its continuation $k$ by broadcasting $\say {i.x}{\Tent}$. Axiom (10) expresses that exclusive area $i.x$ accepts hearing an ${\Tent}$ payload if it is currently not taken; i.e., carries the boolean state $\Tfalse$. This makes the following parallel transition possible:
$$
\begin{array}{c}
  \Trinst {i.r} c \Xs {\TrteEnter x k}
  \Opar
  \Texcl {i.x} \Tfalse \vspace{0.6ex} \\
  \red {\say {i.x} \Tent} \\
  \Trinst {i.r} c {\Tcons x \Xs} {\Tap k \Tvoid}
  \Opar
  \Texcl {i.x} \Ttrue
\end{array}
$$
Exiting from an exclusive area is simply the reverse, as defined in axioms (11) and (12):
$$
\begin{array}{c}
  \Trinst {i.r} c {\Tcons x \Xs} {\TrteExit x k}
  \Opar
  \Texcl {i.x} \Ttrue \vspace{0.6ex} \\
  \red {\say {i.x} \Tex} \\
  \Trinst {i.r} c \Xs {\Tap k \Tvoid}
  \Opar
  \Texcl {i.x} \Tfalse
\end{array}
$$

Because axiom (10) is only defined for exclusive areas in the not taken state, there is no way to derive any parallel transition of the following form:
$$
\begin{array}{c}
  p \Opar {\Texcl {i.x} \Ttrue} \red{\say{i.x}{\Tent}} \ldots \\
\end{array}
$$
This means that any runnable instance in $p$ wishing to enter $x$ is effectively blocked from making progress until some other process in $p$ choses to exit $x$. In the same manner, a process wishing to exit an exclusive area not taken is also effectively blocked. The conditions on exiting are actually stronger than those that govern entering, since axiom (11) is only applicable to a runnable instance for which the exited area $x$ is at the top of its stack of acquired exclusive areas (as expressed by the sequence pattern $\Tcons x \Xs$). An exclusive area can thus only be exited by the process that entered it, and only in the reverse order of entering. Section~\ref{sect:DiscExcl} will bring up some alternatives to this semantics, and also discuss the interpretation of blocked processes in more detail.


\subsection{Unbuffered sending/receiving}

Axioms (13) and (15) define unbuffered interprocess communication from a runnable instance point of view. These transitions are just syntactic variants of shared variable reading and writing (axioms (5) and (7)). A data element (\textbf{delem}) process term contains two pieces of state in addition to its address: a communicated data value and a boolean flag for keeping track of unread writes. Axioms (14) and (16) capture reads and writes to the data value and also set the update flag accordingly. The side-confition in axiom (16) makes the rule apply only if there is a static connection from the data element being written and the address of the matched term (recall that data element storage is associated with the receiving side of a connection). Because AUTOSAR allows sender-receiver communication patterns such that $\Tconnect {i.p.e} a$ and $\Tconnect {i.p.e} b$ are simultaneously true, parallel data element updates like the following are possible:
$$
\begin{array}{c}
  \Trinst {i.r} c \Xs {\TrteWrite {p.e} v k} \,\Opar  \\
  {\Tdelem a \_ \_} \Opar {\Tdelem b \_ \_} \vspace{0.6ex} \\
  \red{\say{i.p.e}{\Twr v}} \\
  \Trinst {i.r} c \Xs {\Tap k \Tvoid} \,\Opar \\
  {\Tdelem a \Ttrue v} \Opar {\Tdelem b \Ttrue v}
\end{array}
$$
As an aside, note that the associativity of the parallel composition operator is made entirely irrelevant by the symmetric shape of transition rules (1) and (2).

Axiom (17) provides another means of intepreting a data element write. It expresses that a runnable set up to trigger on data reception on required data element $a$ should be marked as \textbf{pending} whenever a write occurs on an element connected to $a$. An example may be as follows (assuming $\Tconnect {i.p.e} a$ and $\TdataReceivedEvent b a$:
$$
\begin{array}{c}
  \Trinst {i.r} c \Xs {\TrteWrite {p.e} v k} \,\Opar  \\
  {\Tdelem a \_ \_} \Opar {\Trunnable b t \_ n} \vspace{0.6ex} \\
  \red{\say{i.p.e}{\Twr v}} \\
  \Trinst {i.r} c \Xs {\Tap k \Tvoid} \,\Opar \\
  {\Tdelem a \Ttrue v} \Opar {\Trunnable b t \Tpending n}
\end{array}
$$
Transitions that actually create an instance of a pending runnable will be introduced in Section~\ref{sect:SpawnTerm}.

A data element can also be queried for its update status flag, and be marked as carrying no valid value. Axioms (18)-(21) define the corresponding transitions.


\subsection{Buffered sending/receiving} \label{sect:BufSndRcv}

Buffered interprocess communication (axioms (22) - (30)) is just a minor variant of the unbuffered mechanism, where the single-value store of a \textbf{delem} term is replaced by a \textbf{qelem} process holding a sequence of values. The buffer is consumed from the left (axiom (23)) and extended to the right (axiom (27)). When the buffer is empty, the special value (error code) \textbf{nodata} is returned to receiving runnable instances (axiom (24)). When the buffer is at its maximum capacity, the communicated value is simply dropped (axiom (28)).

However, the AUTOSAR specification requires the send command to inform its caller whether all connected buffers were able to successfully store the communicated value or whether some buffers had it dropped. Such information is naturally expressed as an additional parameter $\Tvar{as}$ in the \emph{snd} transition, listing the addresses of connected \textbf{qelem} processes that have no spare capacity. The preconditions of axioms (27) and (28) ensure that $\Tvar{as}$ reflects the truth, and axioms (25) and (26) feed different error codes to the sender's continuation depending on whether $\Tvar{as}$ is empty or not. By requiring connectivity for all $a$ in $\Tvar{as}$ in axiom (26), the possibility of letting irrelevant addresses in $\Tvar{as}$ cause bogus \textbf{limit} results is outruled.

The following example illustrates a scenario where a sent value is only stored in a subset of the connected buffers. Assuming $\Tconnect {\Tep e p i} a$ and $\Tconnect {\Tep e p i} b$:
$$
\begin{array}{c}
  \Trinst {i.r} c \Xs {\TrteSend {p.e} v k} \,\Opar  \\
  {\Tqelem a 2 \Teps} \Opar {\Tqelem b 2 {\Tcons {v_1} {v_2}}} \vspace{0.6ex} \\
  \red{\say{i.p.e}{\Tsnd v {a_2}}} \\
  \Trinst {i.r} c \Xs {\Tap k \Tlimit} \,\Opar \\
  {\Tqelem a 2 v} \Opar {\Tqelem b 2 {\Tcons {v_1} {v_2}}}
\end{array}
$$


\subsection{Calling a server}

The behavior of client-server communication in AUTOSAR depends on whether a client lists the required server port operation as a synchronous or an asynchronous callpoint (which are mutually exclusive model attributes). In the former case, the call command is treated as if it were immediately followed by a command for retrieving the server result (axiom (31)), whereas in the latter case, the call succeeds immediately and the result has to be retireved explicitly by the client's continuation code (axiom (32)). In both cases, however, an attempt to call the server before it is done processing a previous asynchronous call leads to immediate abortion with the error code \textbf{limit} (axiom (35)).

The AUTOSAR specification restricts client-server connections to the many-to-one pattern only, assigning a dedicated runnable resposible for implementing the offered service. It furthermore forbids runnables to be triggered by any events other than operation invocations of compatible signatures, making it natural to associate the state needed to buffer up server invocations with the server runnables themselves. On the other hand, the specification also introduces timeouts and sequence counters that are private to each connection, which is why our calculus needs process terms that correspond to each required (i.e., client-side) operation as well. Axiom (33) shows how the current sequence counter $m$ blazes a call transition if the client-side operation is not already busy, while the busy case is detected in axiom (36). In axiom (34), a successful call transition causes the client identifier $a$ to be buffered up in the server runnable together with sequence number $m$ and call parameter $v$. Axiom (37) lets a server runnable ignore an aborted call attempt.

Here is an example of how a client runnable instance, a client port operation, and a server runnable interact during a call transition (assuming $\ToperationInvokedEvent b a$, $\Tconnect a {i.p.o}$, and $\TserverCallPointTimeout{i.p.o} t $).
$$
\begin{array}{c}
  {\Trinst {i.r} c \Xs {\TrteCall {p.o} v k}} \,\Opar  \\
  {\Toper {i.p.o} m {\Tdone \Tnodata}} \Opar \\
  {\Trunnable b 0 \Cs 0} \vspace{0.6ex} \\
  \red{\say{i.p.o}{\Tcall m v}} \\
  {\Trinst {i.r} c \Xs {\Tap k \Tok}} \,\Opar \\
  {\Toper {i.p.o} m {\Tcalling t}} \Opar \\
  {\Trunnable b 0 {\Tcons \Cs {\Tclient {i.p.o} m v}}  0}
\end{array}
$$


\subsection{Passing back a server result}

The \emph{result} command can appear as an implicit effect of a previous call command, if the operation invoked is marked as an \emph{synchronousServerCallPoint} (c.f.\ axiom (31)). It can also be referenced explicitly in a client runnable's code, if the current runnable lists the operation as an \emph{asynchronousServerCallPoint}). For the synchronous case, axiom (38) excludes \textbf{nodata} values, which effectively blocks progress of the caller until a server result distinct from \textbf{nodata} has been produced. The asynchronous case of axiom (39) has no value restrictions, so it will happily pass back the \textbf{nodata} tag as well as an indication that a result is not yet available.

The state keeping track of a call's status resides in the \textbf{oper} term of a connection. Axiom (40) defines that \textbf{nodata} is the result provided while a call is open, whereas axiom (41) returns the stored result once a call has completed.

A server runnable instance is identified by a client parameter distinct from $\Tvoid$. Axiom (42) says that when such a runnable instance reaches the end of its code sequence, it must emit the produced value together with the sequence number and \textbf{oper} address of its current invocation, before it is allowed to terminate (see Section~\ref{sect:SpawnTerm}). The addressed \textbf{oper} term reacts according to axiom (43), by completing the call, storing the produced value and increasing its sequence counter in preparation for the next call. However, should the \textbf{oper} timeout counter reach zero before a transition according to (43) can be taken, the client is obliged to unilaterally terminate the call and set the result to error code \textbf{timeout} (axiom (44)). Axiom (45) enables the completion of a call---successfully or via a timeout---to trigger a subscribing runnable (can be distinct from the original client).

Because of call timeouts, server runnables run the risk of producing results that the original client is not waiting for anymore. Detecting such mismatches is the job of sequence numbers, as witnessed by the requirement in axiom (43) that the sequence numbers returned by the server and expected by the client must be identical (variable $m$). However, there must also exist a means for server runnables to simply discard their results, otherwise they would not be able to terminate. Axiom (46) therefore defines an alternative transition for finished servers, applicable on the condition that the returned sequence number does \emph{not} match what the client expects (axiom (47)). By means of axiom (48), runnables can ignore the corresponding transition.

An example of a normal server result interaction can look as follows:
$$
\begin{array}{c}
  {\Trinst b {\Tclient {i.p.o} {91} {v_0}} \Xs {\Treturn v}} \,\Opar  \\
  {\Toper {i.p.o} {91} {\Tcalling t}} \vspace{0.6ex} \\
  \red{\say{i.p.o}{\Tret {91} v}} \\
  {\Trinst b \Tvoid \Xs {\Treturn \Tvoid}} \,\Opar \\
  {\Toper {i.p.o} {92} {\Tdone v}}
\end{array}
$$
As a contrast, this is the behavior observed when a call timeout occurs:
$$
\begin{array}{c}
  {\Trinst b {\Tclient {i.p.o} {91} {v_0}} \Xs {\Treturn v}} \,\Opar  \\
  {\Toper {i.p.o} {91} {\Tcalling 0}} \vspace{0.6ex} \\
  \red{\say{i.p.o}{\Tret {91} \Ttimeout}} \\
  {\Trinst b {\Tclient {i.p.o} {91} {v_0}} \Xs {\Treturn v}} \,\Opar  \\
  {\Toper {i.p.o} {92} {\Tdone \Ttimeout}}
\end{array}
$$
The processes are now in a state where runnable instance $b$ is prohibited from doing a normal return. Progress is only possible via axioms (46) and (47).
$$
\begin{array}{c}
  {\Trinst b {\Tclient {i.p.o} {91} {v_0}} \Xs {\Treturn v}} \,\Opar  \\
  {\Toper {i.p.o} {92} {\Tdone \Ttimeout}} \vspace{0.6ex} \\
  \red{\say{i.p.o}{\Tskip {91}}} \\
  {\Trinst b \Tvoid \Xs {\Treturn \Tvoid}} \,\Opar \\
  {\Toper {i.p.o} {92} {\Tdone \Ttimeout}}
\end{array}
$$


\subsection{Spawning and terminating} \label{sect:SpawnTerm}

Runnables with an activation state distinct from $\Tidle$ or $\Teps$ are amenable to instantiation. Axiom (49) defines this crucial step for runnables triggered by all types of events except server invocation, which is instead handled by axiom (50). Both rules have many details in common:
\begin{itemize}
\item They apply only when the runnable instantiation timer (parameter two) has reached zero.
\item They reset the timer to a model-defined \emph{minimumStartInterval} to disable further instantiation immediately after a new instance is born.
\item They are guarded by the condition that the current number of runnable instances (fourth parameter) is either zero, or the runnable has been defined to accept concurrent invocations.
\item They make the runnable keep track of the new number of instances.
\item They let the new instance inherit the address of its parent runnable.
\item They create the new instance in parallel with its parent (runnable instances is actually the only example of dynamic process creation in this calculus).
\item They initialize the new instance with code according to the model-defined implementation and an empty list of owned exclusive areas.
\end{itemize}
The differences all emanate from the server/non-server distinction:
\begin{itemize}
\item The non-server runnable instance gets a $\Tvoid$ client parameter whereas the server instance is assigned the client tuple from the head of the server's client queue.
\item The non-server runnable toggles back to the $\Tidle$ activation state, while the server just chops of the head of its client queue.
\item Only the server runnable instance is given a non-void parameter, which is taken from the same client queue head.
\end{itemize}
The transition label of axioms (49) and (59) is noteworthy because it is not matched by a corresponding hearing transition; all other process terms just ignore the information that a new runnable instance has been spawned. An example of process instantiation within a parallel context will thus merely be a trivial variant of one of the instantiation axioms, and is therefore left out.

Complementing the notion of spawning is a mechanism for runnable instance termination. An instance with a $\Tvoid$ client parameter (either acquired natively, or via axioms (42) or (46)) transforms into the terminated process $\Tzero$ as defined in axiom (51). Since this term is the unit of parallel process composition, it is silently absorbed by any other process in parallel with it. The instance termination is also noted by the associated runnable parent, which reacts by decrementing its current instance counter (axiom (52)). An example of this interaction follows below.
$$
\begin{array}{c}
  {\Trunnable b t \Act 3} \Opar
  {\Trinst b \Tvoid \Teps {\Treturn v}} \vspace{0.6ex} \\
  \red{\say{i.p.o}{\Tterm}} \\
  {\Trunnable b t \Act 2} \Opar \Tzero \\
  \equiv \\
  {\Trunnable b t \Act 2}
\end{array}
$$


\subsection{Passing time}

In common with most real-time process calculi, the concept of passing time in our calculus is kept separate from the computational work expressed by the say/hear transitions. This has the advantage of freeing the semantics from possessing a particular computation speed, as any finite number of computation steps can be performed before time must advance. On the other hand, it also means that the  limitations of a particular platform cannot be directly studied unless the calculus is complemented with some form of constraint on the work-time relationship. Such an extension is beyond the scope of the current report, though.

The passage of time is captured as a special transition relation $\red {\Tdelta t}$, whose only effect on the related process terms is to decrement any contained time variables by $t$. For some processes time cannot advance until a particular work transition has been taken; this corresponds to time events that must be noted (although not necessarily acted upon) at the exact time instance when they occur. Yet other processes can only take time transitions, which simply means that they represent an idle system that currently has no work to do. Mostly, though, work and time transitions are simltaneously available, indicating that the semantics considers the slightly slower and sligthly faster behavior alternatives to be equally correct.

Most process terms actually ignore the passage of time, which is expressed by axioms (53) to (58). In axiom (59), an \textbf{oper} term in the \textbf{calling} state lets time pass by decrementing its timeout counter. The counter is not allowed to go negative, though, which forces the \textbf{oper} term to handle the timeout once the counter reaches zero (c.f.\ axiom (44)). Axiom (60) defines a similar behavior for the start interval timer of a runnable, although this timer is also allowed to slip behind further time updates once it has reached zero (axiom (61)). The reason for this is that the interval timers do not enforce any particular action when they time out, they just enable new transition options that do not have to be taken immediately.

A timer process, finally, decrements its counter according to axiom (62). When the counter has become zero, the timer is forced to take the $\payload{tick}$ transition of axiom (63), which also resets the counter to its static period value $t_p$. The net effect of such a transition is that the runnable to which the ticking timer belongs is put into the \textbf{pending} state (axiom (64)). An example of a transition sequence involving a time-triggered runnable follows below.
$$
\begin{array}{c}
  {\Trunnable a 0 \Tidle 0} \Opar
  {\Ttimer a {2.5} {0.3}} \vspace{0.6ex} \\
  \red{\Tdelta {0.3}} \\
  {\Trunnable a 0 \Tidle 0} \Opar
  {\Ttimer a {2.5} 0} \vspace{0.6ex} \\
  \red{\say a \Ttick} \\
  {\Trunnable a 0 \Tpending 0} \Opar
  {\Ttimer a {2.5} {2.5}} \vspace{0.6ex} \\
  \red{\say a \Tnew} \\
  {\Trunnable a {0.8} \Tidle 1} \Opar
  {\Ttimer a {2.5} {2.5}} \,\Opar \\
  {\Trinst a \Tvoid \Teps {\Code_1}} \vspace{0.6ex} \\
  \longrightarrow \cdots \longrightarrow \\
  {\Trunnable a {0.8} \Tidle 1} \Opar
  {\Ttimer a {2.5} {2.5}} \,\Opar \\
  {\Trinst a \Tvoid \Teps {\Code_2}} \vspace{0.6ex} \\
  \red{\Tdelta {0.8}} \\
  {\Trunnable a 0 \Tidle 1} \Opar
  {\Ttimer a {2.5} {1.7}} \,\Opar \\
  {\Trinst a \Tvoid \Teps {\Code_2}} \vspace{0.6ex} \\
  \longrightarrow \cdots \longrightarrow \\
  {\Trunnable a 0 \Tidle 1} \Opar
  {\Ttimer a {2.5} {2.5}} \,\Opar \\
  {\Trinst a \Tvoid \Teps {\Treturn \Tvoid}} \vspace{0.6ex} \\
  \red{\say a \Tterm} \\
  {\Trunnable a 0 \Tidle 0} \Opar
  {\Ttimer a {2.5} {1.7}} \vspace{0.6ex} \\
  \red{\Tdelta {1.5}} \cdots \red{\Tdelta {0.2}} \\
  {\Trunnable a 0 \Tidle 0} \Opar
  {\Ttimer a {2.5} 0} \vspace{0.6ex} \\
  \red{\say a \Ttick} \\
  \cdots
\end{array}
$$



\subsection{Ignoring broadcasts} \label{sect:Ignore}

Although our chosen mechanism for coordinating transitions among process terms goes under the name {\em broadcast}, there is no implication that every process must react to everything being said --- the intent is rather that a process term not directly or indirectly addressed in a transition should be allowed to ignore it. One could try to express this as some form of "catch-up" rule $p \red{l} p$, that would apply only if none of the axioms (5) to (64) match $p$ and $l$. However, such a rule would be too liberal, as it would also enable transitions that are deliberately omitted from the previous axioms, like ${\Texcl {i.x} \Ttrue} \red{\say{i.x}{\Tent}} {\Texcl {i.x} \Ttrue}$ (granting entry to an exclusive area already taken). 

Instead we need a more restrictive rule, that applies to processes not addressed by earlier axioms but avoids those previously excluded by restrictive patterns and other side-conditions. To make this idea precise, however, we need to split the rule according to the different forms of $p$ so that the addressing notion of each process type can be individually captured. Axioms (65) to (72) contain the resulting definitions.

Runnable instances and timers can ignore everything being said by others, as they define no hearing transitions proper that need to be excluded here (axioms (65) and (66)). Exclusive areas, inter-runnable variables and operation terms have hearing transitions previously defined, but only for label addresses matching their own; they can thus safely ignore transitions labelled with any other address. 
Axioms (70) to (72) constitute the non-trivial cases, because here there are multiple earlier definitions to exclude, which also link label and process addresses via static model references. Still, it can be verified that each of the axioms (70) to (72) is guarded by an exact negation of the addressing conditions of any previously defined hearing transition for the same process type. 

As an example, consider the example of Section~\ref{sect:BufSndRcv} under the different assumption that only $\Tconnect{{i.p.e} a}$ holds, with no connection from ${i.p.e}$ to $b$.
$$
\begin{array}{c}
  \Trinst {i.r} c \Xs {\TrteSend {p.e} v k} \,\Opar  \\
  {\Tqelem a 2 \Teps} \Opar {\Tqelem b 2 {\Tcons {v_1} {v_2}}} \vspace{0.6ex} \\
  \red{\say{i.p.e}{\Tsnd v \Teps}} \\
  \Trinst {i.r} c \Xs {\Tap k \Tok} \,\Opar \\
  {\Tqelem a 2 v} \Opar {\Tqelem b 2 {\Tcons {v_1} {v_2}}}
\end{array}
$$



\subsection{TODO}

TODO: some links from rules and choices made here to the AUTOSAR spec

\section{Examples}
\label{sec:Examples}

\begin{itemize}
\item More details on the simple examples + a bigger example.
\item Some examples chosen to illustrate the value of a formal calculus
\end{itemize}

\section{Discussion / results}
\label{sec:Disc}

\subsection{Ambiguities and alternative interpretations}
\label{sec:DiscAmb}

\subsection{Clarification proposals and improvements}
\label{sec:DiscImp}

irv without initValue vs.\ delem without initValue -- ``undefined'' vs.\ NO\_DATA at initial read.

Multiple runnables triggered by same OperationInvokedEvent?

Multiple timingEvent for same runnable, possibly with same period?

Timer initial offsets

DataReceivedEvent at Invalidate?

DataReceivedEvent at limit response?

Exclusive area nesting

Return value of qelem write with fanout > 1 and *some* LIMIT failures

Rule and examples of provided delegation port compatibility don't match

Multiple inconsistent CompSpecs

Crashed runnables


\section{Conclusions and Future Work}
\label{sec:Conc}

Return to the limitation - what is the next step (which can be lifted more easily)

\onecolumn
\appendix
\section{Semantic rules}
\label{sec:Rules}

\setcounter{equation}{4}

\subsection{Inter-runnable variables}
\begin{eqnarray}      \InterrunnableVariables  \notag \end{eqnarray}

\subsection{Exclusive areas}
\begin{eqnarray}      \ExclusiveAreas          \notag \end{eqnarray}

\subsection{Unbuffered sending/receiving}
\begin{eqnarray}      \ReadingWriting          \notag \end{eqnarray}

\subsection{Buffered sending/receiving}
\begin{eqnarray}      \SendingReceiving        \notag \end{eqnarray}

%TODO: RuleLong?
\subsection{Calling a server}

\renewcommand\Pcomma{\nonumber \;\text{and}\;}

\begin{eqnarray}      \CallServer              \notag \end{eqnarray}

\renewcommand\Pcomma{\nonumber \\&&\text{and}\;\;}

\subsection{Passing back a server result}
\begin{eqnarray}      \ServerResult            \notag \end{eqnarray}

\subsection{Spawning and terminating}
\begin{eqnarray}      \SpawnTerminate          \notag \end{eqnarray}

\subsection{Passing time}
\begin{eqnarray}      \PassingTime             \notag \end{eqnarray}

%\renewcommand{\Prule}[2]{#1 & \Pif \;\; #2\\}
\subsection{Ignoring broadcasts}
\begin{eqnarray}      \IgnoreBroadcast         \notag \end{eqnarray}

\end{document}
